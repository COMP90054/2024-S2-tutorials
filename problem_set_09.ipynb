{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/COMP90054/2024-S2-tutorials/blob/main/problem_set_09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2X_LFKZ4Tya"
      },
      "source": [
        "# COMP90054 AI Planning for Autonomy\n",
        "### Problem Set 09 - Monte-Carlo tree search"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3RKa5Jh5eDX"
      },
      "source": [
        "\n",
        "## Key takeaways\n",
        "- Understand the basics of MCTS\n",
        "- Compare and contrast online and offline learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsPz8S6XH_HW"
      },
      "source": [
        "### Background:\n",
        "\n",
        "In this workshop, we will consider the example from the lectures of the\n",
        "agent that moves in a 2D grid world. Remember that if the agent tries to\n",
        "move in a particular direction, there is an 80% of success, and a 10%\n",
        "chance of it going to the left or right.\n",
        "\n",
        "\n",
        "The agent is at cell (2,1), in which 2 is the x-coordinate and 1 the y-coordinate (both start from 0).\n",
        "\n",
        "Assume that only action $Down$ has already been expanded from the root node, and $Q((2,1), Down) = -1$ and $N((2,1), Down) = 1$.\n",
        "\n",
        "It samples the following 5 iterations of MCTS, in which all of the actions successfully move in the intended direction:\n",
        "\n",
        "\n",
        "Iteration | Trace    &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;   &nbsp; &nbsp; &nbsp;  &nbsp; &nbsp; &nbsp;               |      Outcome and reward &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;      &nbsp; &nbsp; &nbsp;              \n",
        "----------|------------------------------------|--------------------------\n",
        "1         | $Up$                     |  $simulate = -1$\n",
        "2         | $Right$                      |  $simulate = -1$\n",
        "3         | $Left$                     |  $simulate=1$\n",
        "4         | $Up \\rightarrow Right$ | $simulate = 1$\n",
        "5         | $Up \\rightarrow Down$ |  $simulate = 1$\n",
        "\n",
        "Here, $Up \\rightarrow Right$ means that we select $Up$, then select the 'successful' outcome, then select $Right$.\n",
        "\n",
        "The notation $simulate = G$ means having just expanded a node,\n",
        "simulate from the outcome to receive cumulative reward $G$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-JtMA6q9dXH"
      },
      "source": [
        "# Problem 1. Selection, expansion, simulation, and backpropagation\n",
        "\n",
        "Draw the MCTS tree for this, assuming $\\gamma=1.0$.\n",
        "Calculate all of the Q-values $Q(s,a)$ and the number of times that each state-action pair been selected, $N(s,a)$, after each iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfNCvr5fSf9G"
      },
      "source": [
        "# Problem 2. Action selection\n",
        "\n",
        "Based on your tree, what is the action with the highest expected return?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuS8KffPkAGy"
      },
      "source": [
        "# Problem 3. UCT\n",
        "\n",
        "Based on your tree, which of action, North, South, East, or West,\n",
        "would be more likely to be chosen if we use UCT to probabilistically\n",
        "select the next action? Show your working. Assume that\n",
        "$C_p = \\frac{1}{2}$.\n",
        "\n",
        "Recall that there have been six iterations: the first iteration that choose $Down$ and the five iterations in the table above."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3lmkJq4t5leq",
        "XZ5g9O0YkRh9",
        "wG944kJfyY6W",
        "XXsWjjW6dMnu",
        "mGa1LxTLyf1R",
        "Z04_XS4K-UEG",
        "JaGb4OghItsc",
        "fqy5UkqMPM-Z",
        "xJ6xJ4pxFZGJ",
        "HELVnL-SrHEp"
      ],
      "name": "problem_set_09.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}